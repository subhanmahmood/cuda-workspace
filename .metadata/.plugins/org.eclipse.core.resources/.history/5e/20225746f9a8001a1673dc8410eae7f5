#include <stdio.h>
#include <numeric>
#include <stdlib.h>
#include <cuda.h>
#include <iostream>
#include <fstream>

using namespace std;

#define BLOCK_SIZE 32

__global__ void reduceKernel(float *d_out, float *d_in, float *f_out);

string reduceInvoker(int arraySize) {
	int N = arraySize;
	printf("%i\n", N);

	size_t size = N * sizeof(float);
	size_t size_o = size / BLOCK_SIZE;
	size_t size_f = sizeof(float);

	float h_in[N];
	float h_out[1];

	float *d_in, *d_out, *f_out;

	cudaEvent_t start, stop;
	cudaEventCreate(&start);
	cudaEventCreate(&stop);

	cudaError_t err;

	for (int i = 0; i < N; i++) {
		h_in[i] = 1.0f;
	}

	cudaMalloc((void**) &d_in, size);

	cudaMemcpy(d_in, h_in, size, cudaMemcpyHostToDevice);

	cudaMalloc((void**) &d_out, size_o);
	cudaMalloc((void**) &f_out, size_f);

	int grid_size = N / BLOCK_SIZE;
	printf("Grid Size is: %d\n", grid_size);
	printf("Block Size is: %d\n", BLOCK_SIZE);

	dim3 threadsPerBlock(BLOCK_SIZE);
	dim3 blocks(grid_size);

	cudaEventRecord(start);

	reduceKernel<<<blocks, threadsPerBlock>>>(d_out, d_in, f_out);

	// Wait for GPU to finish before accessing on host

	// err = cudaThreadSynchronize();
	cudaEventRecord(stop);

	err = cudaDeviceSynchronize();
	printf("Run kernel: %s\n", cudaGetErrorString(err));
	printf("\n");

	err = cudaMemcpy(h_out, f_out, size_f, cudaMemcpyDeviceToHost);
	printf("Copy h_out off device: %s\n", cudaGetErrorString(err));
	printf("\n");

	float milliseconds = 0;
	cudaEventElapsedTime(&milliseconds, start, stop);
	printf("Elapsed time was: %f\n", milliseconds);

	float final_reduction = 0.0f;
	printf("And the final reduction is: %f\n", h_out[0]);
	cudaFree(d_in);
	cudaFree(d_out);
	string csv = to_string(arraySize) + "," + to_string(milliseconds) + ","
			+ to_string(BLOCK_SIZE) + "," + to_string(grid_size) + "\n";
	return csv;
}

int main(void) {
	//Open file
	std::ofstream myFile;
	myFile.open("times.csv", std::ofstream::trunc);
	//Write headers
	myFile << "Array Size,Elapsed Time,Block Size,Grid Size\n";

	//Call reduce function invoker for different array sizes
	for (unsigned int i = 1; i <= (1 << 20); i <<= 1) {
		printf("%i\n", i);
		string csv = reduceInvoker(i);
		myFile << csv;
	}

	myFile.close();
}
__global__ void reduceKernel(float* d_out, float* d_in, float *f_out) {
	int myId = threadIdx.x + blockDim.x * blockIdx.x; // ID relative
	int tid = threadIdx.x; // Local ID
	__shared__ float temp[BLOCK_SIZE];
	temp[tid] = d_in[myId];
	__syncthreads();
	// do reduction in shared memory
	for (unsigned int s = blockDim.x / 2; s >= 1; s >>= 1) {
		if (tid < s) {
			temp[tid] += temp[tid + s];
		}
		__syncthreads(); // make sure all adds at one stage are
	}
	// only thread 0 writes result for this block back to global memory
	if (tid == 0) {
		d_out[blockIdx.x] = temp[tid];

		atomicAdd(&f_out[0], d_out[blockIdx.x]);
	}
}
